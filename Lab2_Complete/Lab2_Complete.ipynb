{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D7041-Lab 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "D7041-Lab 2\n",
    "Deborah Aittoklllio debait-2\n",
    "Joel Will√©n Joewil-2\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Language Classification with High-Dimensional Distributed Representations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1: Import Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "\n",
    "\"\"\"Import libraries (numpy, os, re, etc.)\n",
    "Load News Wortschatz Corpora\n",
    "Load Euro Parliament Parallel Corpus\n",
    "Preprocess data (remove punctuation, etc.)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2: Constructing High-Dimensional Centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "\"\"\"\n",
    "Implement n-gram encoding (n=3, tri-grams)\n",
    "Create HD vectors with d=100 and d=1000\n",
    "Build language centroids (21 languages)\n",
    "Answer questions about conventional n-gram representations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.3: Classification using Hyperdimensional Centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "\"\"\"\n",
    "Implement cosine similarity\n",
    "Classify text samples\n",
    "Display confusion matrix\n",
    "Calculate accuracy and F1-score\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Unsupervised Learning with Self-Organizing \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.1: Unsupervised Learning of Hand-Written Digits with SOM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy SOM code from D7041E-lab4_SOM.ipynb\n",
    "# TODO: Adapt code to use MNIST instead of zoo.txt\n",
    "\n",
    "\"\"\"\n",
    "# Step 1: Load the MNIST dataset\n",
    "# TODO: Load MNIST\n",
    "\n",
    "# Step 2: Use the flattened (1D) array of pixels of each image as a feature vector\n",
    "# TODO: Flatten images to 784 features\n",
    "\n",
    "# Step 3: Initialize weights in SOM network randomly, train SOM with grid sizes\n",
    "# TODO: Train SOM with grid 20x20\n",
    "# TODO: Train SOM with grid 40x40\n",
    "# TODO: Train SOM with grid 80x80\n",
    "\n",
    "# Step 4: Display initial, intermediate (at 50%), and final learned weights\n",
    "# TODO: Display initial weights as 28x28 images\n",
    "# TODO: Display intermediate weights (at 50% of iterations) as 28x28 images\n",
    "# TODO: Display final learned weights as 28x28 images\n",
    "\n",
    "# Step 5: Assign labels to neurons by passing TRAINING examples through trained SOM\n",
    "# TODO: Pass training examples and record statistics\n",
    "# TODO: Assign labels to neurons\n",
    "# TODO: Display confusion matrix for TRAINING SET\n",
    "# TODO: Display confusion matrix for TEST SET\n",
    "\n",
    "# Step 6: Experiment with learning rate\n",
    "# TODO: Increase learning rate (fixed iterations)\n",
    "# TODO: Decrease learning rate (fixed iterations)\n",
    "# TODO: Answer: What is the resulting effect?\n",
    "\n",
    "\n",
    "## Question 6: What is the resulting effect of changing learning rate? Answer: [YOUR ANSWER HERE]\n",
    "\n",
    "# Step 7: Experiment with neighborhood decay\n",
    "# TODO: For fixed iterations and best learning rate, increase exponential decay of neighbourhood parameter\n",
    "# TODO: For fixed iterations and best learning rate, decrease exponential decay of neighbourhood parameter\n",
    "\n",
    "\n",
    "## Question 8: What is the effect? Answer: [YOUR ANSWER HERE] \n",
    "## Question 9: What is a biological neuron? How does it relate to the concept of neurons in SOM? Answer: [YOUR ANSWER HERE]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Fundamentals of Artificial Neural Networks and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.1: Multi-layer perceptron and backpropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy backpropagation code from ANN_backprop.ipynb\n",
    "\n",
    "\n",
    "### Task 3.1.1: Understand the implementation structure of the multilayer \n",
    "\"\"\"\n",
    "Task 3.1.a: Be able to explain the principle of backpropagation algorithm Answer: [YOUR ANSWER HERE] \n",
    "Task 3.1.b: Be able to explain the meaning and the role of the Softmax function Answer: [YOUR ANSWER HERE] \n",
    "Task 3.1.c: Be able to name typically used non-linear output functions and implications of choosing one or another for implementation Answer: [YOUR ANSWER HERE] \n",
    "Task 3.1.d: Find the places in the code where execution breaks, answer the questions, comment out the exit line\n",
    "# TODO: Find Question 1 in backpropagate() method\n",
    "# TODO: Answer Question 1: What is computed in the next line of code?\n",
    "\n",
    "\n",
    "Question 1: What is computed in the delta calculation? Answer: [YOUR ANSWER HERE]\n",
    "# TODO: Comment out exit_with_err() for Question 1\n",
    "# TODO: Find Question 2 in backpropagate() method\n",
    "# TODO: Answer Question 2: What does this 'for' loop do?\n",
    "\n",
    "Question 2: What does the backpropagation 'for' loop do? Answer: [YOUR ANSWER HERE]\n",
    "# TODO: Comment out exit_with_err() for Question 2\n",
    "# TODO: Find Question 3 in evaluate() method\n",
    "# TODO: Answer Question 3: How is weight update implemented? What is eta?\n",
    "\n",
    "Question 3: How is weight update implemented? What is eta? Answer: [YOUR ANSWER HERE]\n",
    "# TODO: Comment out exit_with_err() for Question 3\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3.1.2: Run with default hyperparameters\n",
    "# TODO: Run with epochs=70, learning_rate=0.05\n",
    "# TODO: Record classification \n",
    "\n",
    "\"\"\"\n",
    "Question: What is the classification accuracy? Answer: [YOUR ANSWER HERE]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3.1.3: Run with different learning rates\n",
    "# TODO: Run with learning_rate=0.005\n",
    "# TODO: Run with learning_rate=0.5\n",
    "# TODO: Compare results\n",
    "\"\"\"\n",
    "Question: Explain the observed differences in the functionality of the multi-layer perceptron Answer: [YOUR ANSWER HERE] \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3.1.4: Implement ReLU activation function\n",
    "# TODO: Implement f_relu() function with forward pass\n",
    "# TODO: Implement f_relu() derivative\n",
    "# TODO: Run perceptron with ReLU, epochs=70, learning_rate=0.05\n",
    "# TODO: Record classification accuracy with ReLU\n",
    "# TODO: Find learning rate values that give comparable accuracy to Sigmoid\n",
    "\n",
    "\"\"\"\n",
    "Question: What is the classification accuracy with ReLU? Answer: [YOUR ANSWER HERE] Question: What learning rate gives comparable accuracy to Sigmoid? Answer: [YOUR ANSWER HERE]\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
